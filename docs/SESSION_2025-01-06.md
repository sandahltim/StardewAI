# StardewAI Session - January 6, 2025

## What's Working

### Perception (Eyes - Qwen3 VL)
- âœ… Screen capture working
- âœ… Qwen3 VL correctly identifies Stardew Valley scenes
- âœ… Extracts: location, time, objects, player state
- Server: `http://100.104.77.44:8061` (llama.cpp)

### Planning (Brain - Nemotron)
- âœ… Nemotron generates sensible Stardew-specific plans
- âœ… Plans are contextual ("click gift box", "go outside")
- Server: `http://localhost:8034` (llama.cpp with dual GPU)

### Agent Loop
- âœ… Full perceive â†’ plan â†’ (dry-run) execute loop
- âœ… ~8 second cycle time (perception + planning)
- âœ… Logs to `./logs/agent.log`

## Example Output
```
ğŸ‘ï¸ Perceiving...
   Location: House, Time: 6:00 am
   The player is inside their house with furniture and a gift box visible

ğŸ§  Planning...
   Goal: check gift box and go outside
   Step 1: click gift box to collect gift
   Step 2: move to door and go outside

ğŸ¦¾ Executing: click gift box to collect gift
   [DRY RUN] Would execute: click
```

## Server Setup

| Server | Address | Model | Purpose |
|--------|---------|-------|---------|
| Brain | localhost:8034 | gary-nemotron-v9-Q5_K_M | Planning/reasoning |
| Eyes | 100.104.77.44:8061 | Qwen3VL-8B-Instruct-Q4_K_M | Vision/perception |

Both use llama.cpp with OpenAI-compatible API.

## Next Steps

1. **Input Simulation** - Enable actual mouse/keyboard control
   - pyautogui installed
   - Need to map screen coords for clicks
   - Consider vgamepad for split-screen co-op (Player 2 uses controller)

2. **Agent Dialogue** - Let Eyes and Brain converse
   - Brain can ask Eyes for clarification
   - More detailed perception on demand

3. **Game Knowledge** - Teach Stardew mechanics
   - Crop schedules, NPC locations, tool usage
   - Could use RAG or system prompts

4. **Split-Screen Co-op** - The actual goal
   - Stardew supports local split-screen
   - Player 2 uses controller (AI simulates via vgamepad)
   - AI gets its own screen region to watch

## Files

```
/home/tim/StardewAI/
â”œâ”€â”€ README.md
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.yaml          # Server addresses
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ MODEL_TIERS.md
â”‚   â”œâ”€â”€ PYTHON_AGENT.md
â”‚   â”œâ”€â”€ ROADMAP.md
â”‚   â”œâ”€â”€ SESSION_2025-01-06.md  # This file
â”‚   â””â”€â”€ SMAPI_MOD.md
â”œâ”€â”€ src/
â”‚   â””â”€â”€ python-agent/
â”‚       â”œâ”€â”€ agent.py           # Main agent
â”‚       â””â”€â”€ test_vision.py     # Test script
â”œâ”€â”€ venv/                      # Python environment
â””â”€â”€ logs/                      # Screenshots and logs
```

## To Resume

```bash
cd /home/tim/StardewAI
source venv/bin/activate

# Test perception
python src/python-agent/test_vision.py

# Run agent (observe only)
python src/python-agent/agent.py --observe --goal "Water the crops"

# Run agent (with input - BE CAREFUL)
python src/python-agent/agent.py --goal "Water the crops"
```

## Open Questions

1. Split-screen vs two instances for co-op?
2. How to handle AI's screen region in split-screen?
3. Best way to simulate controller input (vgamepad vs SDL)?
4. Should agents have persistent memory across sessions?
